<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>MWSIS</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">MWSIS: Multimodal Weakly Supervised Instance Segmentation with 2D Box Annotations for Autonomous Driving </h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block"><a href="https://github.com/jiangxb98" target="_blank">Guangfeng Jiang</a><sup>1</sup>,</span>
              <span class="author-block"><a href="http://staff.ustc.edu.cn/~junliu/" target="_blank">Jun Liu</a><sup>1*</sup>,</span>
              <span class="author-block">Yuzhi Wu<sup>1</sup></span>
              <span class="author-block">Wenlong Liao<sup>2</sup></span>
              <span class="author-block">Tao He<sup>3</sup></span>
              <span class="author-block"><a href="https://scholar.google.com/citations?user=s8m-hZoAAAAJ&hl=en" target="_blank">Pai Peng</a><sup>3*</sup></span>
            </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block"><sup>1</sup>Department of Electronic Engineering and Information Science, University of Science and Technology of China, </span>
                    <span class="author-block"><sup>2</sup>Shanghai Jiao Tong University, </span>
                    <span class="author-block"><sup>3</sup>COWAROBOT</span><br>AAAI-2024
                    <span class="corresponding-author"><small><br><sup>*</sup>Corresponding author</small></span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <!-- <span class="link-block">
                        <a href="https://arxiv.org/pdf/<ARXIV PAPER ID>.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span> -->

                  <!-- ArXiv abstract Link -->
                  <span class="link-block">
                    <a href="https://arxiv.org/abs/2312.06988" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                    </a>
                  </span>

                  <!-- Supplementary PDF link -->
                  <!-- <span class="link-block">
                    <a href="static/pdfs/appendix.pdf" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Supplementary</span>
                  </a>
                </span> -->

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/jiangxb98/mwsis-plugin" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser video-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
        <!-- Your image here -->
        <img src="static/images/framework.png" alt="MY ALT TEXT"/>
        <!-- <h2 class="subtitle has-text-centered"> -->
          <!-- First image description. -->
        <!-- </h2> -->
      <div class="overview">
        The framework mainly consists of three parts: image pseudo label generation
        branch, point cloud pseudo label generation branch, and CSCS module. In the 2D branch, the pseudo 2D masks generated by
        the IPG module self-supervise the 2D masks. In the 3D branch, the label is refined by the SPG module and PVC module to
        supervise the 3D Masks.Finally, the pseudo masks from the teacher model are used for cross-supervision in the CSCS module.
      </div>
    </div>
  </div>
</section>
<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Instance segmentation is a fundamental research in computer vision, especially in autonomous driving.
            However, manual mask annotation for instance segmentation is quite time-consuming and costly.
            To address this problem, some prior works attempt to apply weakly supervised manner by exploring 2D or 3D boxes.
            However, no one has ever successfully segmented 2D and 3D instances simultaneously by only using 2D box annotations, 
            which could further reduce the annotation cost by an order of magnitude.
          </p>
          <p>
            Thus, we propose a novel framework called Multimodal Weakly Supervised Instance Segmentation (<strong>MWSIS</strong>), 
            which incorporates various fine-grained label correction modules for both 2D and 3D modalities, along 
            with a new multimodal cross-supervision approach. In the 2D pseudo label generation branch, the 
            Instance-based Pseudo Mask Generation (IPG) module utilizes predictions for self-supervised correction.
            Similarly, in the 3D pseudo label generation branch, the Spatial-based Pseudo Label Generation (SPG) 
            module generates pseudo labels by incorporating the spatial prior information of the point cloud. 
            To further refine the generated pseudo labels, the Point-based Voting Label Correction (PVC) module 
            utilizes historical predictions for correction. Additionally, a Ring Segment-based Label Correction (RSC) 
            module is proposed to refine the predictions by leveraging the depth prior information from the point cloud.
            Finally, the Consistency Sparse Cross-modal Supervision (CSCS) module reduces the inconsistency of 
            multimodal predictions by response distillation.
          </p>  
          <p>
            Particularly, transferring the 3D backbone to downstream tasks not only improves the performance 
            of the 3D detectors, but also outperforms fully supervised instance segmentation with only 5% 
            fully supervised annotations.
          </p>  
          <p>
            On the Waymo dataset, the proposed framework demonstrates significant 
            improvements over the baseline, especially achieving 2.59% mAP and 12.75% mAP increases for 2D and 
            3D instance segmentation tasks, respectively.</p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<!-- Paper Contributions -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Contributions</h2>
        <div class="content has-text-justified">
          <p>
            1. To the best of our knowledge, we are the first to use the 2D box annotations as the sole external supervision signal to train both image and point cloud instance segmentors simultaneously.
          </p>
          <p>
            2. We propose various fine-grained label correction modules for different modalities, including instance-based, spatial-based, point-based, and ring segment-based modules. These modules not only enhance the instance segmentation performance, but also improve the quality of the pseudo label.
          </p>  
          <p>
            3. We propose a novel cross-modal supervision method, named CSCS, which exploits the complementary properties of the point cloud and image modalities. This method improves the performance of the segmentors.
          </p>
          <p>
            4. Our framework can be used as a pre-training method to improve the performance of 3D downstream tasks such as semantic segmentation, instance segmentation, and object detection.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<!-- Image container -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Pseudo Label Quality</h2>
      <div class="content has-text-justified">
        <!-- <p>
          <strong>1. Pseudo label quality comparison.</strong>
        </p> -->
        <p>
          Left: Visualizing 3D pseudo labels.
          Right: Comparisons of IoU obtained with different methods on Waymo validation dataset. 
          SAM means the process of obtaining masks through the use of SAM, where 2D boxes are employed as prompts.
        </p>
      </div>
      <div class="columns">
        <div class="column new">
          <img src="static/images/SPG.png" alt="GT Image"/>
          <div class="content has-text-centered">
            <!-- <p>GT Image</p> -->
          </div>
        </div>
        <div class="column new">
          <img src="static/images/SPG2.png" alt="Volume-rendered normals"/>
          <div class="content has-text-centered">
            <!-- <p>Volume-rendered normals</p> -->
          </div>
        </div>
      </div>
</div>
</section>
<!-- End image container -->

<!-- Image container -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Main Results</h2>
      <div class="content has-text-justified">
        <p>
          <strong>2D Instance Segmentation.</strong>
        </p>
      </div>
      <div class="columns">
        <div class="column is-one-quater">
          <img src="static/images/2D-CAR.png" alt="GT Image"/>
          <div class="content has-text-centered">
            <!-- <p>GT Image</p> -->
          </div>
        </div>
        <div class="column is-one-quater">
          <img src="static/images/2D-PED.png" alt="Volume-rendered normals"/>
          <div class="content has-text-centered">
            <!-- <p>Volume-rendered normals</p> -->
          </div>
        </div>
      </div>
      <div class="content has-text-justified">
        <p>
          <strong>3D Instance Segmentation.</strong>
        </p>
      </div>
      <div class="columns">
        <div class="column is-one-quater">
          <img src="static/images/3D.png" alt="GT Image"/>
          <div class="content has-text-centered">
            <!-- <p>GT Image</p> -->
          </div>
      </div>
      </div>
</div>
</section>
<!-- End image container -->

<!-- Image carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Ring Segment</h2>
      <div class="content has-text-justified">
        <p>To leverage the prior information about the depth variation of the point cloud, we propose the
          Depth Clustering Segment (DCS) algorithm to segment the point cloud. </p>
        <p>  
          As shown in the following images, different colors represent different ring segments.</p>
      </div>
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item">
          <!-- Your image here -->
          <img src="static/images/1.jpg" alt="MY ALT TEXT"/>
        </div>
        <div class="item">
          <!-- Your image here -->
          <img src="static/images/2.jpg" alt="MY ALT TEXT"/>
        </div>
        <div class="item">
          <!-- Your image here -->
          <img src="static/images/3.jpg" alt="MY ALT TEXT"/>
        </div>
        <div class="item">
          <!-- Your image here -->
          <img src="static/images/4.jpg" alt="MY ALT TEXT"/>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End image carousel -->


<!-- Paper poster -->
<!-- <section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Poster</h2>

      <iframe  src="static/pdfs/sample.pdf" width="100%" height="550">
          </iframe>
        
      </div>
    </div>
  </section> -->
<!--End paper poster -->

<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@misc{jiang2023mwsis,
        title={MWSIS: Multimodal Weakly Supervised Instance Segmentation with 2D Box Annotations for Autonomous Driving}, 
        author={Guangfeng Jiang and Jun Liu and Yuzhi Wu and Wenlong Liao and Tao He and Pai Peng},
        year={2023},
        eprint={2312.06988},
        archivePrefix={arXiv},
        primaryClass={cs.CV}
  }</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
